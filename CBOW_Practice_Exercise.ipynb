{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahafAlharthi/Projects/blob/master/CBOW_Practice_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuous Bag of Words (CBOW) Model"
      ],
      "metadata": {
        "id": "L4G-WdYBozAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, we will create a CBOW model using a sample Arabic medical corpus. The corpus consists of sentences describing various medical scenarios. The goal of the CBOW model is to predict a target word based on its surrounding context words."
      ],
      "metadata": {
        "id": "RhS9KCVPpSy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Required Libraries"
      ],
      "metadata": {
        "id": "BmX5AlBspz6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we import the necessary libraries to build and train the Continuous Bag of Words (CBOW) model.\n",
        "\n",
        "- **TensorFlow and Keras**: Used to build the neural network model, including the layers like `Embedding`, `Dense`, and `Lambda`.\n",
        "- **Tokenizer**: A utility from Keras for tokenizing and processing text data.\n",
        "- **NumPy**: Used for handling numerical operations, particularly for processing arrays and data manipulation.\n",
        "\n",
        "These libraries will provide the essential tools for text preprocessing and model development in the upcoming steps.\n",
        "\n",
        "Add more if needed!\n"
      ],
      "metadata": {
        "id": "S6Ba2ibzpydu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vLFR0MF1p2Y2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Corpus"
      ],
      "metadata": {
        "id": "-LHg8WazpVFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we initialize the corpus that will be used for training the Continuous Bag of Words (CBOW) model. The corpus consists of Arabic sentences, each of which describes different medical scenarios.\n",
        "\n",
        "- **Corpus**: A collection of medical-related sentences in Arabic, focusing on various health conditions, treatments, and patient experiences.\n",
        "\n",
        "This step sets up the text data that we will use in the upcoming stages of tokenization and model training."
      ],
      "metadata": {
        "id": "aXDrgRcvoliV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"المريض يعاني من ارتفاع في ضغط الدم منذ فترة طويلة ويحتاج إلى تغيير نمط حياته لتجنب المضاعفات\",\n",
        "    \"الطبيب أشار إلى ضرورة إجراء فحوصات شاملة للتأكد من عدم وجود مشاكل أخرى تؤثر على القلب والجهاز التنفسي\",\n",
        "    \"كانت نتائج التحاليل المخبرية تشير إلى انخفاض حاد في نسبة الحديد مما يستدعي البدء في العلاج فوراً\",\n",
        "    \"المستشفى شهد ازدحامًا شديدًا اليوم بسبب تزايد حالات الطوارئ والحالات الحرجة التي وصلت خلال ساعات الصباح\",\n",
        "    \"المريض يحتاج إلى متابعة دورية من أجل التحكم في نسبة السكر في الدم وتجنب أي تدهور في حالته الصحية\",\n",
        "    \"الأشعة أكدت وجود كسر في العظام ويجب على المريض الراحة التامة والالتزام بالعلاج الموصوف من الطبيب\",\n",
        "    \"الجراحة كانت ناجحة والمريض بدأ يشعر بتحسن تدريجي في حالته ولكنه يحتاج إلى فترة نقاهة طويلة قبل العودة إلى نشاطاته\",\n",
        "    \"الطبيب نصح المريض باتباع نظام غذائي صحي وممارسة الرياضة بانتظام للحفاظ على صحته العامة والوقاية من الأمراض\",\n",
        "    \"تم تشخيص المريضة بمرض مزمن يتطلب علاجًا طويل الأمد وتغييرًا جذريًا في نمط الحياة للتعايش معه\",\n",
        "    \"المريض يشعر بألم حاد في الصدر منذ عدة أيام وقد أُحيل إلى قسم القلب لإجراء فحوصات تشخيصية شاملة\",\n",
        "    \"التحليل المخبري أكد وجود التهاب في المسالك البولية ويتطلب العلاج الفوري بالمضادات الحيوية لتفادي أي مضاعفات\",\n",
        "    \"المريض يعاني من أعراض الأنفلونزا الموسمية ولكن حالته مستقرة ولا تحتاج إلى دخول المستشفى\",\n",
        "    \"التهاب المفاصل تسبب في صعوبة الحركة لدى المريضة ويجب عليها البدء في العلاج الطبيعي لتخفيف الألم واستعادة الحركة\",\n",
        "    \"الفحص الطبي الدوري كشف عن ارتفاع في نسبة الكوليسترول مما يستدعي تغييرًا في النظام الغذائي والبدء في العلاج\",\n",
        "    \"المريضة تعاني من اضطرابات النوم بسبب القلق المفرط وقد تمت إحالتها إلى أخصائي نفسي لتقديم الدعم اللازم\",\n",
        "    \"تم اكتشاف ورم في مرحلة مبكرة لدى المريض ويجب إجراء المزيد من الفحوصات لتحديد أفضل خيارات العلاج المتاحة\",\n",
        "    \"التقرير الطبي أشار إلى أن المريض يعاني من مشاكل في الجهاز الهضمي ويحتاج إلى اتباع نظام غذائي خاص لتجنب الألم\",\n",
        "    \"العملية الجراحية التي أجريت كانت ناجحة ولكن المريض يحتاج إلى مراقبة مستمرة للتأكد من عدم حدوث أي مضاعفات\",\n",
        "    \"المريض يعاني من ضيق في التنفس وقد تم نقله إلى وحدة العناية المركزة لتلقي العلاج اللازم بشكل عاجل\",\n",
        "    \"العلاج الطبيعي الذي يخضع له المريض يساعد في تحسين حالته بشكل ملحوظ ولكنه يحتاج إلى الاستمرار لفترة طويلة\"\n",
        "]"
      ],
      "metadata": {
        "id": "qEQJL-CNjjvO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Vocabulary and Model Parameters"
      ],
      "metadata": {
        "id": "TtAp6KPlqBzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we define key parameters that will be used to configure the CBOW model.\n",
        "\n",
        "- **Vocabulary size**: We calculate the size of the vocabulary based on the number of unique words in the corpus. The `vocab_size` represents the total number of unique tokens (words) in the dataset plus one for padding.\n",
        "  \n",
        "- **Embedding size**: The `embedding_size` defines the dimensionality of the word embeddings. In this case, we set the embedding size to 10, meaning each word will be represented as a 10-dimensional vector in the embedding layer.\n",
        "\n",
        "- **Window size**: The `window_size` defines how many words to the left and right of the target word are considered as context. Here, a window size of 2 means that two words before and two words after the target word will be used as context.\n",
        "\n",
        "These parameters will play an essential role in shaping the CBOW model architecture.\n"
      ],
      "metadata": {
        "id": "EOPRl8IfqAHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "print('After converting our words in the corpus into vector of integers:')\n",
        "print(sequences)"
      ],
      "metadata": {
        "id": "icwJ4As2qEkP",
        "outputId": "3b43a5f2-98c0-4806-8fc9-c0114cacd79c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After converting our words in the corpus into vector of integers:\n",
            "[[3, 6, 4, 20, 1, 57, 21, 22, 23, 9, 24, 2, 58, 25, 59, 26, 60], [10, 27, 2, 61, 28, 29, 30, 31, 4, 32, 11, 33, 62, 63, 12, 34, 64, 65], [13, 66, 67, 68, 69, 2, 70, 35, 1, 14, 71, 36, 37, 38, 1, 5, 72], [39, 73, 74, 75, 76, 40, 77, 78, 79, 80, 81, 41, 82, 83, 84, 85], [3, 7, 2, 86, 87, 4, 88, 89, 1, 14, 90, 1, 21, 91, 15, 92, 1, 8, 93], [94, 95, 11, 96, 1, 97, 16, 12, 3, 98, 99, 100, 101, 102, 4, 10], [103, 13, 42, 104, 105, 43, 106, 107, 1, 8, 44, 7, 2, 23, 108, 9, 109, 110, 2, 111], [10, 112, 3, 113, 45, 46, 114, 115, 116, 117, 118, 12, 119, 120, 121, 4, 122], [17, 123, 18, 124, 125, 126, 127, 128, 129, 130, 131, 1, 25, 132, 133, 134], [3, 43, 135, 35, 1, 136, 22, 137, 138, 19, 139, 2, 140, 34, 141, 29, 142, 30], [143, 144, 145, 11, 47, 1, 146, 147, 148, 5, 149, 150, 151, 152, 15, 48], [3, 6, 4, 153, 154, 155, 49, 8, 156, 157, 158, 2, 159, 39], [47, 160, 161, 1, 162, 50, 51, 18, 16, 163, 38, 1, 5, 52, 164, 53, 165, 50], [166, 54, 167, 168, 169, 20, 1, 14, 170, 36, 37, 171, 1, 172, 173, 174, 1, 5], [18, 175, 4, 176, 177, 40, 178, 179, 19, 180, 181, 2, 182, 183, 184, 185, 55], [17, 186, 187, 1, 188, 189, 51, 3, 16, 28, 190, 4, 191, 192, 193, 194, 5, 195], [196, 54, 27, 2, 197, 3, 6, 4, 33, 1, 198, 199, 24, 2, 200, 45, 46, 201, 26, 53], [202, 203, 41, 204, 13, 42, 49, 3, 7, 2, 205, 206, 31, 4, 32, 207, 15, 48], [3, 6, 4, 208, 1, 209, 19, 17, 210, 2, 211, 212, 213, 214, 5, 55, 56, 215], [5, 52, 216, 217, 218, 3, 219, 1, 220, 8, 56, 221, 44, 7, 2, 222, 223, 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_size = 10\n",
        "window_size = 2"
      ],
      "metadata": {
        "id": "8596ULpRWCp7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Context-Target Pairs for CBOW"
      ],
      "metadata": {
        "id": "w6b35855qQqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we generate the context-target pairs from the tokenized sequences to train the CBOW model.\n",
        "\n",
        "- **Context words**: For each word in a sequence, the surrounding words (within the window size) are considered as context. The context consists of the words immediately before and after the target word.\n",
        "  \n",
        "- **Target word**: The word in the middle of the context window is treated as the target word that the model will learn to predict.\n",
        "\n",
        "We iterate through each sequence, collecting the context words and corresponding target words:\n",
        "- For each word in a sequence, we gather the surrounding words based on the defined window size.\n",
        "- The middle word is the target, and the surrounding words form the context.\n",
        "\n",
        "Finally:\n",
        "- **`X`**: An array of context words.\n",
        "- **`y`**: The target words are one-hot encoded, which means they are converted into a categorical format where each word is represented as a vector of length equal to the vocabulary size.\n",
        "\n",
        "These context-target pairs will be used to train the CBOW model to predict a target word based on its context.\n"
      ],
      "metadata": {
        "id": "589xXbYmqEuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = []\n",
        "targets = []\n",
        "for sequence in sequences:\n",
        "    for i in range(window_size, len(sequence) - window_size):\n",
        "        context = sequence[i - window_size:i] + sequence[i + 1:i + window_size + 1]\n",
        "        target = sequence[i]\n",
        "        contexts.append(context)\n",
        "        targets.append(target)\n",
        "X = np.array(contexts)\n",
        "y = tf.keras.utils.to_categorical(targets, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "c8c1MkYOqSfd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and Training the CBOW Model"
      ],
      "metadata": {
        "id": "hgxmB4fZqU1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we build and train the Continuous Bag of Words (CBOW) model using the context-target pairs created earlier.\n",
        "\n",
        "1. **Model architecture**:\n",
        "   - **Embedding layer**: This layer transforms the input context words into dense vector representations (embeddings) of size defined by `embedding_size`. The `input_dim` is set to the vocabulary size, and the `input_length` is twice the window size (since context consists of words from both sides of the target).\n",
        "   \n",
        "   - **Lambda layer**: This layer computes the mean of the context word embeddings. It averages the embeddings of the context words to generate a single representation that will be used to predict the target word.\n",
        "   \n",
        "   - **Dense layer**: This fully connected layer outputs a probability distribution over the vocabulary, using the softmax activation function. It predicts the most likely target word based on the context word embeddings.\n",
        "\n",
        "2. **Compilation**:\n",
        "   The model is compiled using the Adam optimizer and categorical cross-entropy as the loss function, which is suitable for multi-class classification tasks. Accuracy is used as a metric to evaluate the model's performance during training.\n",
        "\n",
        "3. **Training the model**:\n",
        "   The model is trained on the context-target pairs for 500 epochs. During each epoch, the model learns to predict the target word based on the context, refining its weights to improve accuracy.\n",
        "\n",
        "4. **Saving the model weights**:\n",
        "   After training, the model weights are saved to a file (`cbow_model.weights.h5`) for future use. This allows us to load the trained model later without retraining.\n",
        "\n",
        "By the end of this step, the CBOW model will have learned to predict target words based on their surrounding context from the given corpus."
      ],
      "metadata": {
        "id": "QkXe33DgqSvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2*window_size))\n",
        "model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "model.save_weights('cbow_model.weights.h5')"
      ],
      "metadata": {
        "id": "vL3UZZe3qhhh",
        "outputId": "16bb7eb4-e54d-4cea-bae3-49830ae0bc89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0104 - loss: 5.4113  \n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0665 - loss: 5.4056 \n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0906 - loss: 5.4013 \n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0894 - loss: 5.3974 \n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0964 - loss: 5.3928 \n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 5.3871 \n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1241 - loss: 5.3816 \n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1497 - loss: 5.3740 \n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1485 - loss: 5.3685 \n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1347 - loss: 5.3636 \n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1338 - loss: 5.3576 \n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1393 - loss: 5.3508 \n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1152 - loss: 5.3442 \n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1336 - loss: 5.3332 \n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1073 - loss: 5.3285 \n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1345 - loss: 5.3183 \n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1472 - loss: 5.3052 \n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1096 - loss: 5.2991 \n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1246 - loss: 5.2873 \n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1141 - loss: 5.2754 \n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1142 - loss: 5.2654  \n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1274 - loss: 5.2484 \n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1204 - loss: 5.2350 \n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1103 - loss: 5.2308 \n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1263 - loss: 5.2059 \n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1251 - loss: 5.1844 \n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1346 - loss: 5.1745 \n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 5.1647 \n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1110 - loss: 5.1288 \n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1105 - loss: 5.1245 \n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0939 - loss: 5.1075 \n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0829 - loss: 5.1109 \n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 5.0791 \n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1363 - loss: 5.0401 \n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1302 - loss: 5.0050 \n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1187 - loss: 4.9960 \n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1200 - loss: 4.9753  \n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1286 - loss: 4.9571 \n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1397 - loss: 4.9187 \n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1421 - loss: 4.9123 \n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1210 - loss: 4.8985 \n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1074 - loss: 4.8984 \n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1701 - loss: 4.7904 \n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1238 - loss: 4.8345 \n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1366 - loss: 4.7987 \n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1560 - loss: 4.7456 \n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1325 - loss: 4.7244 \n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1319 - loss: 4.7085 \n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1157 - loss: 4.6868 \n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1389 - loss: 4.7015 \n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1417 - loss: 4.6460 \n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1397 - loss: 4.6098 \n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1408 - loss: 4.5790 \n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1448 - loss: 4.5565  \n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1373 - loss: 4.5155 \n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1392 - loss: 4.5154 \n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1662 - loss: 4.4482 \n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1617 - loss: 4.4471 \n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1552 - loss: 4.4279 \n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1488 - loss: 4.4154 \n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1534 - loss: 4.3684 \n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1921 - loss: 4.3101 \n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1387 - loss: 4.3511 \n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1456 - loss: 4.3162 \n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1714 - loss: 4.2845 \n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1375 - loss: 4.2939 \n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1538 - loss: 4.2773 \n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1656 - loss: 4.1971  \n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1532 - loss: 4.2198  \n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1760 - loss: 4.1788  \n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1639 - loss: 4.1479 \n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1861 - loss: 4.0826 \n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1778 - loss: 4.1354 \n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2104 - loss: 4.0269 \n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2043 - loss: 3.9844  \n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1998 - loss: 4.0155 \n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1789 - loss: 3.9992 \n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1977 - loss: 3.9099  \n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1841 - loss: 3.9455 \n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2162 - loss: 3.8583  \n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2086 - loss: 3.8681  \n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1960 - loss: 3.9313  \n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2031 - loss: 3.8878  \n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2307 - loss: 3.7712  \n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2168 - loss: 3.7706  \n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2183 - loss: 3.7896 \n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1990 - loss: 3.7997  \n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1874 - loss: 3.7768  \n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2193 - loss: 3.7543  \n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1987 - loss: 3.7674  \n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2252 - loss: 3.6240 \n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2285 - loss: 3.6993 \n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2165 - loss: 3.6830 \n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2185 - loss: 3.6936 \n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2199 - loss: 3.6144 \n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2209 - loss: 3.6070  \n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2439 - loss: 3.5608 \n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2487 - loss: 3.4712 \n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2225 - loss: 3.5742 \n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2555 - loss: 3.5212 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting a Word Using the Trained CBOW Model"
      ],
      "metadata": {
        "id": "mLodiHWkqaL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we define a function to predict a word based on a given context using the trained CBOW model.\n",
        "\n",
        "1. **Function: `predict_word`**:\n",
        "   - **Input**: The function takes a list of context words as input. The number of context words should match the expected size (2 times the window size).\n",
        "   - **Context sequence conversion**: The input context words are tokenized into a sequence of integers using the same tokenizer that was used during training.\n",
        "   - **Input validation**: The function checks whether the length of the context sequence matches the expected size (2 times the window size). If not, it prints an error message.\n",
        "   - **Prediction**: The tokenized context is fed into the trained CBOW model, which predicts the probability distribution over the vocabulary.\n",
        "   - **Retrieve predicted word**: The predicted word is the one with the highest probability. The function retrieves the word corresponding to the predicted index from the tokenizer's word index.\n",
        "\n",
        "2. **Example**:\n",
        "   - We provide a sample context: `['في', 'ارتفاع', 'يعاني', 'المريض']`.\n",
        "   - The function predicts the word that fits best in this context, based on the model's learned weights.\n",
        "   - The predicted word is printed along with the input context.\n",
        "\n",
        "This function allows us to test the CBOW model by predicting words based on their surrounding context from the corpus."
      ],
      "metadata": {
        "id": "_SRP_chYqYKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_word(context_words, tokenizer, model, window_size):\n",
        "    \"\"\"\n",
        "    Predict the target word based on a given context using a trained CBOW model.\n",
        "\n",
        "    Args:\n",
        "    - context_words (list of str): The context words surrounding the target word.\n",
        "    - tokenizer (Tokenizer): The tokenizer used to convert words to integers.\n",
        "    - model (tf.keras.Model): The trained CBOW model.\n",
        "    - window_size (int): The size of the context window used in training.\n",
        "\n",
        "    Returns:\n",
        "    - str: The predicted target word.\n",
        "    \"\"\"\n",
        "    # Tokenize the context words\n",
        "    context_sequence = tokenizer.texts_to_sequences([context_words])\n",
        "\n",
        "    # Flatten the sequence (context sequence should be a 2D list)\n",
        "    context_sequence = np.array(context_sequence).flatten()\n",
        "\n",
        "    # Validate the length of context_sequence\n",
        "    expected_length = 2 * window_size\n",
        "    if len(context_sequence) != expected_length:\n",
        "        print(f\"Error: Expected {expected_length} context words, but got {len(context_sequence)}.\")\n",
        "        return None\n",
        "\n",
        "    # Prepare the input for the model\n",
        "    context_sequence = np.expand_dims(context_sequence, axis=0)\n",
        "\n",
        "    # Predict the probabilities for each word in the vocabulary\n",
        "    predictions = model.predict(context_sequence)\n",
        "\n",
        "    # Get the index of the word with the highest probability\n",
        "    predicted_index = np.argmax(predictions[0])\n",
        "\n",
        "    # Retrieve the predicted word from the tokenizer's word index\n",
        "    reverse_word_index = {v: k for k, v in tokenizer.word_index.items()}\n",
        "    predicted_word = reverse_word_index.get(predicted_index, \"Unknown\")\n",
        "\n",
        "    # Print the result\n",
        "    print(f\"Context: {context_words}\")\n",
        "    print(f\"Predicted Word: {predicted_word}\")\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have:\n",
        "# - `tokenizer` as your trained tokenizer\n",
        "# - `model` as your trained CBOW model\n",
        "# - `window_size` as the size of the context window used during training\n",
        "# - `context_words` as the list of context words\n",
        "\n",
        "context_words = ['في', 'ارتفاع', 'يعاني', 'المريض']\n",
        "predicted_word = predict_word(context_words, tokenizer, model, window_size)\n"
      ],
      "metadata": {
        "id": "ykhSWJY0qgCI",
        "outputId": "a28d5da9-f234-42b7-bf4c-1972a6d5a139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Context: ['في', 'ارتفاع', 'يعاني', 'المريض']\n",
            "Predicted Word: من\n"
          ]
        }
      ]
    }
  ]
}